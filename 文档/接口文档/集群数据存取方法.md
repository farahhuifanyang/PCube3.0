#  918集群数据读取方法

## 机器

| 名称    | 主从   | IP和端口号           | 内存     | 磁盘      |
| :---- | ---- | ---------------- | ------ | ------- |
| cdh01/pcube-cluster-01 | 主    | 10.105.242.73:22 | 62.7GB | 525.5GB |
| cdh02/pcube-cluster-02 | 从    | 10.105.242.74:22 | 62.7GB | 3.6TB   |
| cdh03/pcube-cluster-03 | 从    | 10.105.242.72:22 | 62.7GB | 246.7GB |

## 集群管理

http://pcube-cluster-01:7180/

账号：admin

密码：admin

## HDFS

NameNode：cdh01

web端可视化文件管理：http://pcube-cluster-01:9870/explorer.html#/

python使用hdfs包进行操作

### 安装

pip install hdfs

### 连接HDFS

from hdfs.client import Client

client = Client("10.105.242.73:9870")

### 常用API

* list(hdfs_path, status=False)

  获取指定路径的子目录信息，例如列出所有hdfs目录，client.list("/")。

  hdfs_path：hdfs路径。

  status：True时，也返回子目录的状态信息，默认为Flase。

* status(hdfs_path, strict=True)

  获取路径的具体信息。

  strict：设置为True时，如果hdfs_path路径不存在就会抛出异常。设置为False时，如果路径为不存在，则返回None。

* makedirs(hdfs_path, permission=None)

  创建目录，例如client.makedirs("/test")。

  permission：设置权限。

* delete(hdfs_path, recursive=False)

  删除。

  recursive：删除文件和其子目录，设置为False如果不存在，则会抛出异常，默认为False。

* upload(hdfs_path, local_path, overwrite=False, n_threads=1, temp_dir=None, chunk_size=65536,progress=None, cleanup=True, **kwargs)

  上传数据，例如client.upload("/test","/home/myhadoop/test.txt")。

  overwrite：是否是覆盖性上传文件。

  n_threads：启动的线程数目。

  temp_dir：当overwrite=true时，远程文件一旦存在，则会在上传完之后进行交换。

  chunk_size：文件上传的大小区间。

  progress：回调函数来跟踪进度，为每一chunk_size字节。它将传递两个参数，文件上传的路径和传输的字节数。一旦完成，-1将作为第二个参数。

  cleanup：如果在上传任何文件时发生错误，则删除该文件。

* download(hdfs_path, local_path, overwrite=False, n_threads=1, temp_dir=None, **kwargs)

  下载数据。

  参数同upload。

### 其他

hdfs的全部API可以查看官网：https://hdfscli.readthedocs.io/en/latest/api.html

## HBase

Master：cdh01/pcube-cluster-01

HBase Web UI：http://pcube-cluster-01:16010/master-status

使用happybase包操作

### 安装

pip install happybase

### 连接HBase

happybase.Connection(host=’localhost’, port=9090, timeout=None, autoconnect=True, table_prefix=None, table_prefix_separator=b’_’, compat=’0.98’, transport=’buffered’, protocol=’binary’)

​	host：主机名

​	port：端口

​	timeout：超时时间

​	autoconnect：连接是否直接打开

​	table_prefix：用于构造表名的前缀，命名空间

​	table_prefix_separator：用于table_prefix的分隔符

​	compat：兼容模式

​	transport：运输模式

​	protocol：协议

例：connection = happybase.Connection(host='10.105.242.73', table_prefix='PCube')

### 常用API---连接(happybase.Connection)

* open()

  打开传输，无返回值

* close()

  关闭传输，无返回值

* compact_table(name,major=False)

  压缩指定表格，无返回值

  name：表名

  major：是否主要压缩

* create_table(name,families)

  创建表，无返回值

  families：列族

  例如：

  ```python
  # 例一
  families = {
      "cf":dict(),
      "df":dict()
  }
  connection.create_table(name,families) # 如果有表前缀参数时，真实表名为'table_prefix'_'name'
  # 例二
  connection.create_table(
      'my_table',
      {
          'cf1': dict(max_versions=10),
          'cf2': dict(max_versions=1, block_cache_enabled=False),
          'cf3': dict(),  # use defaults
      }
  )
  ```

* delete_table(name,disable=False)

  删除表，无返回值

  disable：是否先禁用表

* disable_table(name)

  禁用表，无返回值

* enable_table(name)

  启用表，无返回值

* is_table_enabled(name)

  表是否已经被启用，返回一个bool值

* connection.table(name,user_prefix=True)

  获取一个表对象，返回一个happybase.Table对象

  user_prefix：是否使用表前缀，默认为True

* connection.tables()

  获取Hbase实例中的表名列表，返回一个list

### 常用API---表(happybase.Table)

* happybase.Table(name,connection)

  获取表实例

  name：表名

  connection：连接

* cells(row, column, versions=None, timestamp=None, include_timestamp=False)

  获取单元格数据，返回一个list

  row：行

  column：列

  versions：获取的最大版本数量，默认None，即获取所有

  timestamp：时间戳，默认None，即获取所有时间戳版本的数据。可指定一个时间戳，获取小于此时间戳版本的所有数据

  include_timestamp：是否返回时间戳，默认False

* counter_set(row,column,value=0)

  设置计数器列为特定值，此方法在指定列中存储一个64位有符号整数值，无返回值

  value：默认值，默认为0

* counter_get(row,column)

  获取计数器列的值，返回当前单元格的值

* counter_dec(row,column,value=1)

  计数器列递减，返回递减后单元格的值

  value：每次递减的值，默认为1

* counter_inc(row,column,value=1)

  计数器列递增，返回递增后单元格的值

  value：每次递增的值，默认为1

* delete(row, columns=None, timestamp=None, wal=True)

  删除指定行数据，无返回值

  timestamp：时间戳，默认为None，即删除所有，可传入一个时间戳来删除小于等于此时间戳的所有数据

  wal：是否写入wal，默认为True

* families()

  获取所有列族信息，返回一个dict

* put(row, data, timestamp=None, wal=True)

  插入一行数据，如果row key已经存在，则变成了修改数据，无返回值

  data: 数据，dict类型，{列:值}构成，列与值皆为str类型

  timestamp：时间戳，默认None，即写入当前时间戳

  wal：是否写入wal，默认为True

### 核工业实例

```python
import happybase


# connection = happybase.Connection(host='10.112.235.173', table_prefix='nuclear_system') #第二个参数是命名空间
# table_name_list = connection.tables()

# print(table_name_list)
# connection.create_table(    #创建情报表，创建一次就可
#     'Intelligence',         #表名
#     {'Intelligence_details': dict()}#max_versions=1, block_cache_enabled=False ，列族的相关配置
# )


def Intelligence_Dao(Intelligences):
    connection = happybase.Connection(host='10.112.235.173',
                                      table_prefix='nuclear_system')
    connection.open()
    table = connection.table('Intelligence')  # 连接表
    bat = table.batch()
    for num, Intelligence in enumerate(Intelligences):  # 传入的是一个对象列表，迭代写入
        result = Intelligence.to_dict()
        data = {
            # 'Intelligence_details:id':result['id'],
            'Intelligence_details:url': result['url'],
            'Intelligence_details:time': result['time'],
            'Intelligence_details:title': result['title'],
            'Intelligence_details:content': result['content'],
            'Intelligence_details:nucleus_cls': result['nucleus_cls'],
            'Intelligence_details:key': result['key'],  # 关键字[v1,v2,v3....]
            'Intelligence_details:sentiment': result['sentiment'],
            'Intelligence_details:summary': result['summary'],
            'Intelligence_details:language': result['language'],
            'Intelligence_details:path': result['path'],
        }

        bat.put(result['id'], data)
        if num > 0 and num % 10 == 0:
            bat.send()
    bat.send()
    connection.close()
```

## Neo4j
- 本文安装社区驱动py2neo并使用，也可使用官方驱动neo4j
### 安装
`pip install py2neo`

### 导入
`from py2neo import Graph, Node, Relationship`

### 连接neo4j
`graph = Graph('http://pcube-cluster-01:7474',username='xxx',password='xxx')`

### 示例代码
```python
## 创建结点
node_1 = Node(label='entity', name='ccy')
node_2 = Node(label='entity', name='lft')
node_3 = Node(label='entity', name='zhm')
graph.create(node_1)
graph.create(node_2)
graph.create(node_3)
 
## 创建关系
# 分别建立了node_1指向node_2和node_2指向node_1两条关系，关系的类型为"上级、下级"，两条关系都有属性count，且值为1。
relation_between_node1_and_node2 = Relationship(node_1, 'superior', node_2)
relation_between_node1_and_node2['count'] = 1
relation_between_node2_and_node1 = Relationship(node_2, 'subordinate', node_1)
relation_between_node2_and_node3 = Relationship(node_2, 'classmate', node_3)
relation_between_node2_and_node1['count'] = 1
 
graph.create(relation_between_node1_and_node2)
graph.create(relation_between_node2_and_node1)
graph.create(relation_between_node2_and_node3)
```

## ElasticSearch

### 安装
`pip install elasticsearch5`

### 导入并连接ES
```python
from elasticsearch5 import Elasticsearch
# elasticsearch集群服务器的地址
ES = [
    'pcube-cluster-01:9200'
]

# 创建elasticsearch客户端
es = Elasticsearch(
    ES,
    # 启动前嗅探es集群服务器
    sniff_on_start=True,
    # es集群服务器结点连接异常时是否刷新es节点信息
    sniff_on_connection_fail=True,
    # 每60秒刷新节点信息
    sniffer_timeout=60
)
```

### 常用API
#### 创建索引
```python
#创建索引，索引的名字是my-index,如果已经存在了，就返回个400，
#这个索引可以现在创建，也可以在后面插入数据的时候再临时创建
es.indices.create(index='my-index',ignore)
```

#### 搜索数据
- 两种方式 get and search

  - get方式

  ```python
  #get获取
  res = es.get(index="my-index", doc_type="test-type", id=01)
  es.get(index='indexName', doc_type='typeName', id='idValue')
  ```

  - search方式
  ```python
  body = {
      "query":{
          "terms":{
              "name":[
                  "python","android"
              ]
          }
      }
  }
  # 搜索出name="python"或name="android"的所有数据
  res = es.search(index="my_index",doc_type="test_type",body=body)


  # match:匹配name包含python关键字的数据
  body = {
      "query":{
          "match":{
              "name":"python"
          }
      }
  }
  # 查询name包含python关键字的数据
  es.search(index="my_index",doc_type="test_type",body=body)

  # multi_match:在name和addr里匹配包含深圳关键字的数据
  body = {
      "query":{
          "multi_match":{
              "query":"深圳",
              "fields":["name","addr"]
          }
      }
  }
  # 查询name和addr包含"深圳"关键字的数据
  es.search(index="my_index",doc_type="test_type",body=body)

  # 更多搜索用法可以参照 <https://blog.csdn.net/u013429010/article/details/81746179>
  ```
#### 插入数据
```python
# 插入字段any为data01, timestamp字段为datetime.now()的数据
es.index(index="my-index",doc_type="test-type",id=01,body={"any":"data01","timestamp":datetime.now()})
```

#### 删除数据
 - delete：删除指定index、type、id的文档
  ```python
  es.delete(index='indexName', doc_type='typeName', id='idValue')
  ```
 - delete_by_query：删除满足条件的所有数据，查询条件必须符合DLS格式
  ```python
  query = {'query': {'match': {'sex': 'famale'}}}# 删除性别为女性的所有文档

  query = {'query': {'range': {'age': {'lt': 11}}}}# 删除年龄小于11的所有文档

  es.delete_by_query(index='indexName', body=query, doc_type='typeName')
  ```

#### 条件更新
- update_by_query：更新满足条件的所有数据，写法同上delete_by_query